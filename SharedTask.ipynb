{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import re\n",
    "from scipy.stats.stats import pearsonr   \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anger = pd.read_csv(\"EI-reg-en_anger_train.txt\", header=None, names=[\"text\", \"emotion\", \"intensity\"], sep=\"\t\")\n",
    "df_fear = pd.read_csv(\"EI-reg-en_fear_train.txt\", header=None, names=[\"text\", \"emotion\", \"intensity\"], sep=\"\t\")\n",
    "df_joy = pd.read_csv(\"EI-reg-en_joy_train.txt\", header=None, names=[\"text\", \"emotion\", \"intensity\"], sep=\"\t\")\n",
    "df_sadness = pd.read_csv(\"EI-reg-en_sadness_train.txt\", header=None, names=[\"text\", \"emotion\", \"intensity\"], sep=\"\t\")\n",
    "df = df_anger.append([df_fear, df_joy, df_sadness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"emotion\"] = pd.Categorical(df[\"emotion\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41523</th>\n",
       "      <td>@ITdominiccoyle @IrishTimesBiz Between Barroso...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41524</th>\n",
       "      <td>@pottermore : I can't find my patronus, the we...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41525</th>\n",
       "      <td>Nutella is pine green forget me nots are ivory...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41526</th>\n",
       "      <td>I was not made for this world. #empath #unhappy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41527</th>\n",
       "      <td>She used to be beautiful, but she lived her li...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41528</th>\n",
       "      <td>Why does Candice constantly pout #GBBO ðŸ’„ðŸ˜’</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41529</th>\n",
       "      <td>@redBus_in #unhappy with #redbus CC, when I ta...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41530</th>\n",
       "      <td>@AceOperative789 no pull him afew weeks ago, s...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41531</th>\n",
       "      <td>I'm buying art supplies and I'm debating how s...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41532</th>\n",
       "      <td>@sainsburys Could you ask your Chafford Hundre...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  intensity\n",
       "41523  @ITdominiccoyle @IrishTimesBiz Between Barroso...        3      0.458\n",
       "41524  @pottermore : I can't find my patronus, the we...        3      0.729\n",
       "41525  Nutella is pine green forget me nots are ivory...        3      0.125\n",
       "41526    I was not made for this world. #empath #unhappy        3      0.750\n",
       "41527  She used to be beautiful, but she lived her li...        3      0.398\n",
       "41528          Why does Candice constantly pout #GBBO ðŸ’„ðŸ˜’        3      0.396\n",
       "41529  @redBus_in #unhappy with #redbus CC, when I ta...        3      0.604\n",
       "41530  @AceOperative789 no pull him afew weeks ago, s...        3      0.479\n",
       "41531  I'm buying art supplies and I'm debating how s...        3      0.375\n",
       "41532  @sainsburys Could you ask your Chafford Hundre...        3      0.438"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PIPELINE WITHOUT INCORPORATING THE EMOTION FEATURE\n",
    "pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer(use_idf=True)),\n",
    "    ('classifier', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.29013908027270746, 8.6589669175317977e-36)\n",
      "[[ 1.          0.29013908]\n",
      " [ 0.29013908  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"intensity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(pearsonr(y_test, y_pred))\n",
    "print(np.corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.37413374403823801, 4.1089960537085461e-60)\n",
      "[[ 1.          0.37413374]\n",
      " [ 0.37413374  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "class EmotionExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'emotion': text}\n",
    "                for text in posts]\n",
    "    \n",
    "# pipeline that does incorporate both text and emotion features\n",
    "pipeline2 = Pipeline([\n",
    "\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ])),\n",
    "\n",
    "            ('emotion', Pipeline([\n",
    "                ('selector', ItemSelector(key='emotion')),\n",
    "                ('stats', EmotionExtractor()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "        ],\n",
    "\n",
    "        # give equal weights to text and emotion features\n",
    "        transformer_weights={\n",
    "            'text': 0.5,\n",
    "            'emotion': 0.5,\n",
    "            },\n",
    "        )),\n",
    "        ('classifier', LinearRegression())\n",
    "        ])\n",
    "X = df[[\"emotion\", \"text\"]]\n",
    "y = df[\"intensity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipeline2.fit(X_train, y_train)\n",
    "y_pred = pipeline2.predict(X_test)\n",
    "\n",
    "print(pearsonr(y_test, y_pred))\n",
    "print(np.corrcoef(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
